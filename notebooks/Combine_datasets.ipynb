{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a85fe8",
   "metadata": {},
   "source": [
    "Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11870e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf564c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "136a4b44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d30541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2209746/3463678343.py:2: DtypeWarning: Columns (1,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('data/raw/output_async.csv')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/raw/porn-with-dates-2022.csv')\n",
    "df2 = pd.read_csv('data/raw/output_async.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aada33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df1: ['url', 'title', 'categories', 'date', 'views', 'upvotes', 'downvotes', 'production', 'comments', 'actors']\n",
      "Columns in df2: ['url', '_upload_date', '_votes_up', '_views', '_categories', '_tags', '_title']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in df1:\", df1.columns.tolist())\n",
    "print(\"Columns in df2:\", df2.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82a3c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_renamed = df2.rename(columns={\n",
    "    '_title': 'title',\n",
    "    '_categories': 'categories',\n",
    "    '_upload_date': 'date',\n",
    "    '_views': 'views',\n",
    "    '_votes_up': 'upvotes',\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11421358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df1: ['url', 'title', 'categories', 'date', 'views', 'upvotes', 'downvotes', 'production', 'comments', 'actors']\n",
      "Columns in df2_renamed: ['url', 'date', 'upvotes', 'views', 'categories', '_tags', 'title']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in df1:\", df1.columns.tolist())\n",
    "print(\"Columns in df2_renamed:\", df2_renamed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d19f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 434600\n",
      "Remaining after cleaning: 38122\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = ['title', 'categories', 'date', 'views', 'upvotes']\n",
    "df2_renamed.replace('', pd.NA, inplace=True)\n",
    "# Drop rows where all specified metadata fields are missing\n",
    "df2_renamed_cleaned = df2_renamed.dropna(subset=metadata_cols, how='all')\n",
    "print(f\"Original rows: {len(df2_renamed)}\")\n",
    "print(f\"Remaining after cleaning: {len(df2_renamed_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8afbd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df1, df2_renamed_cleaned], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203eaaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'title', 'categories', 'date', 'views', 'upvotes', 'downvotes',\n",
       "       'production', 'comments', 'actors', '_tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96b96cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ['Babe', 'Big Tits', 'Brunette', 'HD Porn', 'H...\n",
       "1         ['Blowjob', 'HD Porn', 'Hardcore', 'MILF', 'Ro...\n",
       "2         ['Big Tits', 'Brunette', 'Cumshot', 'HD Porn',...\n",
       "3         ['Amateur', 'Anal', 'Creampie', 'HD Porn', 'Ha...\n",
       "4         ['Amateur', 'Blonde', 'Brunette', 'Fingering',...\n",
       "                                ...                        \n",
       "256121                                                  NaN\n",
       "256122    Anal;Blowjob;Bondage;Brunette;Creampie;HD Porn...\n",
       "256123    Amateur;Big Tits;Blonde;College (18+);Ebony;Ex...\n",
       "256124    Amateur;Anal;Big Dick;Exclusive;Female Orgasm;...\n",
       "256125    18-25;Amateur;Behind The Scenes;Female Orgasm;...\n",
       "Name: categories, Length: 256126, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4670a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def normalize_categories(val):\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    try:\n",
    "        # Try to parse stringified list\n",
    "        parsed = ast.literal_eval(val)\n",
    "        if isinstance(parsed, list):\n",
    "            return parsed\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    # Fallback: split on semicolon\n",
    "    return [x.strip() for x in val.split(';')]\n",
    "\n",
    "combined_df['categories'] = combined_df['categories'].apply(normalize_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44b1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [Babe, Big Tits, Brunette, HD Porn, Handjob, T...\n",
       "1         [Blowjob, HD Porn, Hardcore, MILF, Rough Sex, ...\n",
       "2         [Big Tits, Brunette, Cumshot, HD Porn, Latina,...\n",
       "3         [Amateur, Anal, Creampie, HD Porn, Hardcore, POV]\n",
       "4         [Amateur, Blonde, Brunette, Fingering, HD Porn...\n",
       "                                ...                        \n",
       "256121                                                   []\n",
       "256122    [Anal, Blowjob, Bondage, Brunette, Creampie, H...\n",
       "256123    [Amateur, Big Tits, Blonde, College (18+), Ebo...\n",
       "256124    [Amateur, Anal, Big Dick, Exclusive, Female Or...\n",
       "256125    [18-25, Amateur, Behind The Scenes, Female Org...\n",
       "Name: categories, Length: 256126, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a022e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2008-01-01 to 2024-08-08\n"
     ]
    }
   ],
   "source": [
    "combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')\n",
    "min_date = combined_df['date'].min()\n",
    "max_date = combined_df['date'].max()\n",
    "\n",
    "print(f\"Date range: {min_date.date()} to {max_date.date()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1b356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2008.0      763\n",
      "2009.0     9051\n",
      "2010.0     8413\n",
      "2011.0     6942\n",
      "2012.0    11053\n",
      "2013.0    24605\n",
      "2014.0    27111\n",
      "2015.0    25599\n",
      "2016.0    27891\n",
      "2017.0    29525\n",
      "2018.0    52746\n",
      "2019.0     2557\n",
      "2020.0     4557\n",
      "2021.0     6608\n",
      "2022.0     5947\n",
      "2023.0     6778\n",
      "2024.0     2837\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_df['year'] = combined_df['date'].dt.year\n",
    "year_counts = combined_df['year'].value_counts().sort_index()\n",
    "print(year_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5be2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('data/raw/data2008-2024.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
